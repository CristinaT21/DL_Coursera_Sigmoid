Epoch 1
-------------------------------
loss: 0.693986  [    0/  398]
Epoch 1
-------------------------------
loss: 0.200151  [    0/  398]
Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.5)
Path to dataset files: C:\Users\crist\.cache\kagglehub\datasets\uciml\breast-cancer-wisconsin-data\versions\2
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 569 entries, 0 to 568
Data columns (total 33 columns):
 #   Column                   Non-Null Count  Dtype
---  ------                   --------------  -----
 0   id                       569 non-null    int64
 1   diagnosis                569 non-null    object
 2   radius_mean              569 non-null    float64
 3   texture_mean             569 non-null    float64
 4   perimeter_mean           569 non-null    float64
 5   area_mean                569 non-null    float64
 6   smoothness_mean          569 non-null    float64
 7   compactness_mean         569 non-null    float64
 8   concavity_mean           569 non-null    float64
 9   concave points_mean      569 non-null    float64
 10  symmetry_mean            569 non-null    float64
 11  fractal_dimension_mean   569 non-null    float64
 12  radius_se                569 non-null    float64
 13  texture_se               569 non-null    float64
 14  perimeter_se             569 non-null    float64
 15  area_se                  569 non-null    float64
 16  smoothness_se            569 non-null    float64
 17  compactness_se           569 non-null    float64
 18  concavity_se             569 non-null    float64
 19  concave points_se        569 non-null    float64
 20  symmetry_se              569 non-null    float64
 21  fractal_dimension_se     569 non-null    float64
 22  radius_worst             569 non-null    float64
 23  texture_worst            569 non-null    float64
 24  perimeter_worst          569 non-null    float64
 25  area_worst               569 non-null    float64
 26  smoothness_worst         569 non-null    float64
 27  compactness_worst        569 non-null    float64
 28  concavity_worst          569 non-null    float64
 29  concave points_worst     569 non-null    float64
 30  symmetry_worst           569 non-null    float64
 31  fractal_dimension_worst  569 non-null    float64
 32  Unnamed: 32              0 non-null      float64
dtypes: float64(31), int64(1), object(1)
memory usage: 146.8+ KB
C:\Users\crist\AppData\Local\Temp\ipykernel_16836\1762497399.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  data['diagnosis'] = data['diagnosis'].replace({'M': 1, 'B': 0})
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 569 entries, 0 to 568
Data columns (total 31 columns):
 #   Column                   Non-Null Count  Dtype
---  ------                   --------------  -----
 0   diagnosis                569 non-null    int64
 1   radius_mean              569 non-null    float64
 2   texture_mean             569 non-null    float64
 3   perimeter_mean           569 non-null    float64
 4   area_mean                569 non-null    float64
 5   smoothness_mean          569 non-null    float64
 6   compactness_mean         569 non-null    float64
 7   concavity_mean           569 non-null    float64
 8   concave points_mean      569 non-null    float64
 9   symmetry_mean            569 non-null    float64
 10  fractal_dimension_mean   569 non-null    float64
 11  radius_se                569 non-null    float64
 12  texture_se               569 non-null    float64
 13  perimeter_se             569 non-null    float64
 14  area_se                  569 non-null    float64
 15  smoothness_se            569 non-null    float64
 16  compactness_se           569 non-null    float64
 17  concavity_se             569 non-null    float64
 18  concave points_se        569 non-null    float64
 19  symmetry_se              569 non-null    float64
 20  fractal_dimension_se     569 non-null    float64
 21  radius_worst             569 non-null    float64
 22  texture_worst            569 non-null    float64
 23  perimeter_worst          569 non-null    float64
 24  area_worst               569 non-null    float64
 25  smoothness_worst         569 non-null    float64
 26  compactness_worst        569 non-null    float64
 27  concavity_worst          569 non-null    float64
 28  concave points_worst     569 non-null    float64
 29  symmetry_worst           569 non-null    float64
 30  fractal_dimension_worst  569 non-null    float64
dtypes: float64(30), int64(1)
memory usage: 137.9 KB
Shape of X [N, C, H, W]:  torch.Size([32, 30])
Shape of y:  torch.Size([32, 1]) torch.float32
Epoch 1
-------------------------------
loss: 0.687666  [    0/  398]
Epoch 1
-------------------------------
loss: 0.195826  [    0/  398]
Test Error:
 Accuracy: 95.9%, Avg loss: 0.075710

Epoch 2
-------------------------------
loss: 0.183290  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.096244

Epoch 3
-------------------------------
loss: 0.126924  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.123264

Epoch 4
-------------------------------
loss: 0.007492  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.146947

Epoch 5
-------------------------------
loss: 0.006789  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.102158

Epoch 6
-------------------------------
loss: 0.011173  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.127124

Epoch 7
-------------------------------
loss: 0.017418  [    0/  398]
Test Error:
 Accuracy: 97.7%, Avg loss: 0.202214

Epoch 8
-------------------------------
loss: 0.028793  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.137305

Epoch 9
-------------------------------
loss: 0.010802  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.165916

Epoch 10
-------------------------------
loss: 0.000390  [    0/  398]
Test Error:
 Accuracy: 95.9%, Avg loss: 0.159019

Done!
Running experiment with ReLU, SGD, LR=0.001, Batch=32
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 569 entries, 0 to 568
Data columns (total 31 columns):
 #   Column                   Non-Null Count  Dtype
---  ------                   --------------  -----
 0   diagnosis                569 non-null    int64
 1   radius_mean              569 non-null    float64
 2   texture_mean             569 non-null    float64
 3   perimeter_mean           569 non-null    float64
 4   area_mean                569 non-null    float64
 5   smoothness_mean          569 non-null    float64
 6   compactness_mean         569 non-null    float64
 7   concavity_mean           569 non-null    float64
 8   concave points_mean      569 non-null    float64
 9   symmetry_mean            569 non-null    float64
 10  fractal_dimension_mean   569 non-null    float64
 11  radius_se                569 non-null    float64
 12  texture_se               569 non-null    float64
 13  perimeter_se             569 non-null    float64
 14  area_se                  569 non-null    float64
 15  smoothness_se            569 non-null    float64
 16  compactness_se           569 non-null    float64
 17  concavity_se             569 non-null    float64
 18  concave points_se        569 non-null    float64
 19  symmetry_se              569 non-null    float64
 20  fractal_dimension_se     569 non-null    float64
 21  radius_worst             569 non-null    float64
 22  texture_worst            569 non-null    float64
 23  perimeter_worst          569 non-null    float64
 24  area_worst               569 non-null    float64
 25  smoothness_worst         569 non-null    float64
 26  compactness_worst        569 non-null    float64
 27  concavity_worst          569 non-null    float64
 28  concave points_worst     569 non-null    float64
 29  symmetry_worst           569 non-null    float64
 30  fractal_dimension_worst  569 non-null    float64
dtypes: float64(30), int64(1)
memory usage: 137.9 KB
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 569 entries, 0 to 568
Data columns (total 33 columns):
 #   Column                   Non-Null Count  Dtype
---  ------                   --------------  -----
 0   id                       569 non-null    int64
 1   diagnosis                569 non-null    object
 2   radius_mean              569 non-null    float64
 3   texture_mean             569 non-null    float64
 4   perimeter_mean           569 non-null    float64
 5   area_mean                569 non-null    float64
 6   smoothness_mean          569 non-null    float64
 7   compactness_mean         569 non-null    float64
 8   concavity_mean           569 non-null    float64
 9   concave points_mean      569 non-null    float64
 10  symmetry_mean            569 non-null    float64
 11  fractal_dimension_mean   569 non-null    float64
 12  radius_se                569 non-null    float64
 13  texture_se               569 non-null    float64
 14  perimeter_se             569 non-null    float64
 15  area_se                  569 non-null    float64
 16  smoothness_se            569 non-null    float64
 17  compactness_se           569 non-null    float64
 18  concavity_se             569 non-null    float64
 19  concave points_se        569 non-null    float64
 20  symmetry_se              569 non-null    float64
 21  fractal_dimension_se     569 non-null    float64
 22  radius_worst             569 non-null    float64
 23  texture_worst            569 non-null    float64
 24  perimeter_worst          569 non-null    float64
 25  area_worst               569 non-null    float64
 26  smoothness_worst         569 non-null    float64
 27  compactness_worst        569 non-null    float64
 28  concavity_worst          569 non-null    float64
 29  concave points_worst     569 non-null    float64
 30  symmetry_worst           569 non-null    float64
 31  fractal_dimension_worst  569 non-null    float64
 32  Unnamed: 32              0 non-null      float64
dtypes: float64(31), int64(1), object(1)
memory usage: 146.8+ KB
C:\Users\crist\AppData\Local\Temp\ipykernel_16836\1762497399.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  data['diagnosis'] = data['diagnosis'].replace({'M': 1, 'B': 0})
Shape of X [N, C, H, W]:  torch.Size([32, 30])
Shape of y:  torch.Size([32, 1]) torch.float32
Running experiment with ReLU, SGD, LR=0.001, Batch=32
loss: 0.701850  [    0/  398]
Test Error:
 Accuracy: 58.5%, Avg loss: 0.695959

loss: 0.675455  [    0/  398]
Test Error:
 Accuracy: 62.6%, Avg loss: 0.681380

loss: 0.678650  [    0/  398]
Test Error:
 Accuracy: 66.1%, Avg loss: 0.672865

loss: 0.675253  [    0/  398]
Test Error:
 Accuracy: 73.1%, Avg loss: 0.662709

loss: 0.676370  [    0/  398]
Test Error:
 Accuracy: 80.1%, Avg loss: 0.660748

loss: 0.647044  [    0/  398]
Test Error:
 Accuracy: 80.7%, Avg loss: 0.645932

loss: 0.653428  [    0/  398]
Test Error:
 Accuracy: 84.2%, Avg loss: 0.637521

loss: 0.646132  [    0/  398]
Test Error:
 Accuracy: 85.4%, Avg loss: 0.627143

loss: 0.620820  [    0/  398]
Test Error:
 Accuracy: 87.7%, Avg loss: 0.618343

loss: 0.597336  [    0/  398]
Test Error:
 Accuracy: 88.9%, Avg loss: 0.611103

Running experiment with ReLU, SGD, LR=0.001, Batch=64
loss: 0.691897  [    0/  398]
Test Error:
 Accuracy: 65.5%, Avg loss: 0.684247

loss: 0.681454  [    0/  398]
Test Error:
 Accuracy: 70.8%, Avg loss: 0.678422

loss: 0.674964  [    0/  398]
Test Error:
 Accuracy: 72.5%, Avg loss: 0.672367

loss: 0.669844  [    0/  398]
Test Error:
 Accuracy: 78.4%, Avg loss: 0.666018

loss: 0.676780  [    0/  398]
Test Error:
 Accuracy: 80.1%, Avg loss: 0.659616

loss: 0.645578  [    0/  398]
Test Error:
 Accuracy: 84.2%, Avg loss: 0.654728

loss: 0.659000  [    0/  398]
Test Error:
 Accuracy: 85.4%, Avg loss: 0.648364

loss: 0.652257  [    0/  398]
Test Error:
 Accuracy: 86.0%, Avg loss: 0.643298

loss: 0.648032  [    0/  398]
Test Error:
 Accuracy: 88.9%, Avg loss: 0.638656

loss: 0.634281  [    0/  398]
Test Error:
 Accuracy: 89.5%, Avg loss: 0.632759

Running experiment with ReLU, SGD, LR=0.0001, Batch=32
loss: 0.679881  [    0/  398]
Test Error:
 Accuracy: 70.2%, Avg loss: 0.685501

loss: 0.682208  [    0/  398]
Test Error:
 Accuracy: 70.8%, Avg loss: 0.684601

loss: 0.684997  [    0/  398]
Test Error:
 Accuracy: 71.3%, Avg loss: 0.680938

loss: 0.689471  [    0/  398]
Test Error:
 Accuracy: 71.9%, Avg loss: 0.681176

loss: 0.678174  [    0/  398]
Test Error:
 Accuracy: 71.9%, Avg loss: 0.680162

loss: 0.653762  [    0/  398]
Test Error:
 Accuracy: 72.5%, Avg loss: 0.679418

loss: 0.669689  [    0/  398]
Test Error:
 Accuracy: 73.1%, Avg loss: 0.678913

loss: 0.674461  [    0/  398]
Test Error:
 Accuracy: 73.1%, Avg loss: 0.678838

loss: 0.671153  [    0/  398]
Test Error:
 Accuracy: 73.7%, Avg loss: 0.673604

loss: 0.677502  [    0/  398]
Test Error:
 Accuracy: 73.7%, Avg loss: 0.673392

Running experiment with ReLU, SGD, LR=0.0001, Batch=64
loss: 0.679379  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.688785

loss: 0.687986  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.685422

loss: 0.697889  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.685371

loss: 0.679303  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.687131

loss: 0.677970  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.688061

loss: 0.698875  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.687945

loss: 0.697132  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.688454

loss: 0.667029  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.684317

loss: 0.688020  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.684290

loss: 0.699826  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.685486

Running experiment with ReLU, Adam, LR=0.001, Batch=32
loss: 0.685749  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.104885

loss: 0.041193  [    0/  398]
Test Error:
 Accuracy: 94.7%, Avg loss: 0.141121

loss: 0.009533  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.190055

loss: 0.005472  [    0/  398]
Test Error:
 Accuracy: 95.9%, Avg loss: 0.190877

loss: 0.021932  [    0/  398]
Test Error:
 Accuracy: 94.7%, Avg loss: 0.153154

loss: 0.037405  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.187380

loss: 0.004470  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.158364

loss: 0.002821  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.161204

loss: 0.001496  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.172839

loss: 0.004604  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.201853

Running experiment with ReLU, Adam, LR=0.001, Batch=64
loss: 0.679118  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.135767

loss: 0.106302  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.101013

loss: 0.035858  [    0/  398]
Test Error:
 Accuracy: 95.9%, Avg loss: 0.118429

loss: 0.020513  [    0/  398]
Test Error:
 Accuracy: 95.9%, Avg loss: 0.128459

loss: 0.057738  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.126025

loss: 0.029216  [    0/  398]
Test Error:
 Accuracy: 94.7%, Avg loss: 0.170742

loss: 0.005895  [    0/  398]
Test Error:
 Accuracy: 94.7%, Avg loss: 0.138793

loss: 0.005955  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.179856

loss: 0.002480  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.193266

loss: 0.016834  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.169339

Running experiment with ReLU, Adam, LR=0.0001, Batch=32
loss: 0.697048  [    0/  398]
Test Error:
 Accuracy: 94.7%, Avg loss: 0.495019

loss: 0.507014  [    0/  398]
Test Error:
 Accuracy: 94.7%, Avg loss: 0.364908

loss: 0.307149  [    0/  398]
Test Error:
 Accuracy: 94.7%, Avg loss: 0.274364

loss: 0.222965  [    0/  398]
Test Error:
 Accuracy: 94.7%, Avg loss: 0.199843

loss: 0.220748  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.163330

loss: 0.221915  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.165409

loss: 0.097261  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.144843

loss: 0.118089  [    0/  398]
Test Error:
 Accuracy: 95.9%, Avg loss: 0.119866

loss: 0.148408  [    0/  398]
Test Error:
 Accuracy: 95.9%, Avg loss: 0.152181

loss: 0.063909  [    0/  398]
Test Error:
 Accuracy: 95.9%, Avg loss: 0.128428

Running experiment with ReLU, Adam, LR=0.0001, Batch=64
loss: 0.690817  [    0/  398]
Test Error:
 Accuracy: 94.2%, Avg loss: 0.580616

loss: 0.596733  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.490938

loss: 0.484420  [    0/  398]
Test Error:
 Accuracy: 95.9%, Avg loss: 0.416293

loss: 0.376194  [    0/  398]
Test Error:
 Accuracy: 94.7%, Avg loss: 0.355524

loss: 0.355881  [    0/  398]
Test Error:
 Accuracy: 94.7%, Avg loss: 0.297330

loss: 0.257496  [    0/  398]
Test Error:
 Accuracy: 94.7%, Avg loss: 0.257222

loss: 0.297868  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.213153

loss: 0.209460  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.196906

loss: 0.206994  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.176190

loss: 0.140084  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.155369

Running experiment with Sigmoid, SGD, LR=0.001, Batch=32
loss: 0.699289  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.656001

loss: 0.620976  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.650192

loss: 0.645339  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.658742

loss: 0.774000  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.653483

loss: 0.644810  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.648143

loss: 0.659049  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.652867

loss: 0.687506  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.647365

loss: 0.627923  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.656559

loss: 0.626667  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.655973

loss: 0.705140  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.650786

Running experiment with Sigmoid, SGD, LR=0.001, Batch=64
loss: 0.722374  [    0/  398]
Test Error:
 Accuracy: 36.3%, Avg loss: 0.703627

loss: 0.707020  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.686868

loss: 0.682762  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.675932

loss: 0.676798  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.672444

loss: 0.671824  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.664601

loss: 0.665466  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.661306

loss: 0.618186  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.660250

loss: 0.696861  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.659042

loss: 0.643291  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.655095

loss: 0.671401  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.655834

Running experiment with Sigmoid, SGD, LR=0.0001, Batch=32
loss: 0.750462  [    0/  398]
Test Error:
 Accuracy: 36.3%, Avg loss: 0.720647

loss: 0.704354  [    0/  398]
Test Error:
 Accuracy: 36.3%, Avg loss: 0.724265

loss: 0.722505  [    0/  398]
Test Error:
 Accuracy: 36.3%, Avg loss: 0.717291

loss: 0.726660  [    0/  398]
Test Error:
 Accuracy: 36.3%, Avg loss: 0.709884

loss: 0.718059  [    0/  398]
Test Error:
 Accuracy: 36.3%, Avg loss: 0.704735

loss: 0.709592  [    0/  398]
Test Error:
 Accuracy: 36.3%, Avg loss: 0.701940

loss: 0.693632  [    0/  398]
Test Error:
 Accuracy: 35.7%, Avg loss: 0.698344

loss: 0.697320  [    0/  398]
Test Error:
 Accuracy: 34.5%, Avg loss: 0.693625

loss: 0.693301  [    0/  398]
Test Error:
 Accuracy: 68.4%, Avg loss: 0.691120

loss: 0.691577  [    0/  398]
Test Error:
 Accuracy: 65.5%, Avg loss: 0.687861

Running experiment with Sigmoid, SGD, LR=0.0001, Batch=64
loss: 0.706212  [    0/  398]
Test Error:
 Accuracy: 36.3%, Avg loss: 0.709104

loss: 0.701280  [    0/  398]
Test Error:
 Accuracy: 36.3%, Avg loss: 0.706081

loss: 0.707909  [    0/  398]
Test Error:
 Accuracy: 36.3%, Avg loss: 0.704816

loss: 0.705412  [    0/  398]
Test Error:
 Accuracy: 36.3%, Avg loss: 0.702842

loss: 0.700062  [    0/  398]
Test Error:
 Accuracy: 36.3%, Avg loss: 0.700736

loss: 0.705592  [    0/  398]
Test Error:
 Accuracy: 36.3%, Avg loss: 0.699650

loss: 0.701930  [    0/  398]
Test Error:
 Accuracy: 34.5%, Avg loss: 0.697742

loss: 0.697238  [    0/  398]
Test Error:
 Accuracy: 25.1%, Avg loss: 0.696041

loss: 0.695852  [    0/  398]
Test Error:
 Accuracy: 39.8%, Avg loss: 0.694422

loss: 0.694087  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.692843

Running experiment with Sigmoid, Adam, LR=0.001, Batch=32
loss: 0.706372  [    0/  398]
Test Error:
 Accuracy: 70.2%, Avg loss: 0.487221

loss: 0.460832  [    0/  398]
Test Error:
 Accuracy: 93.6%, Avg loss: 0.251234

loss: 0.301801  [    0/  398]
Test Error:
 Accuracy: 94.7%, Avg loss: 0.194752

loss: 0.253731  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.126020

loss: 0.226730  [    0/  398]
Test Error:
 Accuracy: 95.9%, Avg loss: 0.114226

loss: 0.106621  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.112288

loss: 0.057706  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.101536

loss: 0.035418  [    0/  398]
Test Error:
 Accuracy: 94.7%, Avg loss: 0.122354

loss: 0.074834  [    0/  398]
Test Error:
 Accuracy: 95.9%, Avg loss: 0.125106

loss: 0.015513  [    0/  398]
Test Error:
 Accuracy: 94.7%, Avg loss: 0.121472

Running experiment with Sigmoid, Adam, LR=0.001, Batch=64
loss: 0.715403  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.559817

loss: 0.571346  [    0/  398]
Test Error:
 Accuracy: 85.4%, Avg loss: 0.391918

loss: 0.398433  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.263316

loss: 0.214029  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.179720

loss: 0.193194  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.150201

loss: 0.122757  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.123409

loss: 0.105736  [    0/  398]
Test Error:
 Accuracy: 95.9%, Avg loss: 0.109981

loss: 0.080409  [    0/  398]
Test Error:
 Accuracy: 94.7%, Avg loss: 0.123689

loss: 0.073869  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.121544

loss: 0.041468  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.105578

Running experiment with Sigmoid, Adam, LR=0.0001, Batch=32
loss: 0.697110  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.627790

loss: 0.610713  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.599921

loss: 0.552751  [    0/  398]
Test Error:
 Accuracy: 65.5%, Avg loss: 0.568688

loss: 0.674163  [    0/  398]
Test Error:
 Accuracy: 73.7%, Avg loss: 0.542864

loss: 0.594681  [    0/  398]
Test Error:
 Accuracy: 74.9%, Avg loss: 0.507550

loss: 0.519322  [    0/  398]
Test Error:
 Accuracy: 80.1%, Avg loss: 0.475109

loss: 0.457662  [    0/  398]
Test Error:
 Accuracy: 90.6%, Avg loss: 0.439182

loss: 0.454666  [    0/  398]
Test Error:
 Accuracy: 90.1%, Avg loss: 0.417247

loss: 0.380989  [    0/  398]
Test Error:
 Accuracy: 93.6%, Avg loss: 0.388616

loss: 0.321694  [    0/  398]
Test Error:
 Accuracy: 94.2%, Avg loss: 0.342356

Running experiment with Sigmoid, Adam, LR=0.0001, Batch=64
loss: 0.665885  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.637293

loss: 0.630947  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.618294

loss: 0.631231  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.600908

loss: 0.589702  [    0/  398]
Test Error:
 Accuracy: 64.9%, Avg loss: 0.583882

loss: 0.650386  [    0/  398]
Test Error:
 Accuracy: 68.4%, Avg loss: 0.564281

loss: 0.551697  [    0/  398]
Test Error:
 Accuracy: 70.2%, Avg loss: 0.546769

loss: 0.576150  [    0/  398]
Test Error:
 Accuracy: 74.3%, Avg loss: 0.526627

loss: 0.546406  [    0/  398]
Test Error:
 Accuracy: 79.5%, Avg loss: 0.506204

loss: 0.507154  [    0/  398]
Test Error:
 Accuracy: 85.4%, Avg loss: 0.486924

loss: 0.500633  [    0/  398]
Test Error:
 Accuracy: 87.1%, Avg loss: 0.469175

Running experiment with Tanh, SGD, LR=0.001, Batch=32
loss: 0.821368  [    0/  398]
Test Error:
 Accuracy: 16.4%, Avg loss: 0.740414

loss: 0.746452  [    0/  398]
Test Error:
 Accuracy: 56.7%, Avg loss: 0.686438

loss: 0.693992  [    0/  398]
Test Error:
 Accuracy: 92.4%, Avg loss: 0.638559

loss: 0.643995  [    0/  398]
Test Error:
 Accuracy: 95.9%, Avg loss: 0.597677

loss: 0.582245  [    0/  398]
Test Error:
 Accuracy: 95.9%, Avg loss: 0.562155

loss: 0.558557  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.531956

loss: 0.519560  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.498517

loss: 0.486334  [    0/  398]
Test Error:
 Accuracy: 97.7%, Avg loss: 0.472535

loss: 0.444912  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.447429

loss: 0.455720  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.433269

Running experiment with Tanh, SGD, LR=0.001, Batch=64
loss: 0.688322  [    0/  398]
Test Error:
 Accuracy: 76.0%, Avg loss: 0.647848

loss: 0.649089  [    0/  398]
Test Error:
 Accuracy: 79.5%, Avg loss: 0.626883

loss: 0.624411  [    0/  398]
Test Error:
 Accuracy: 85.4%, Avg loss: 0.602838

loss: 0.601841  [    0/  398]
Test Error:
 Accuracy: 86.0%, Avg loss: 0.581574

loss: 0.591124  [    0/  398]
Test Error:
 Accuracy: 87.1%, Avg loss: 0.562567

loss: 0.569826  [    0/  398]
Test Error:
 Accuracy: 88.9%, Avg loss: 0.546221

loss: 0.556717  [    0/  398]
Test Error:
 Accuracy: 90.6%, Avg loss: 0.527275

loss: 0.506823  [    0/  398]
Test Error:
 Accuracy: 91.2%, Avg loss: 0.513011

loss: 0.511006  [    0/  398]
Test Error:
 Accuracy: 92.4%, Avg loss: 0.497635

loss: 0.499086  [    0/  398]
Test Error:
 Accuracy: 92.4%, Avg loss: 0.482955

Running experiment with Tanh, SGD, LR=0.0001, Batch=32
loss: 0.745668  [    0/  398]
Test Error:
 Accuracy: 40.4%, Avg loss: 0.727367

loss: 0.745312  [    0/  398]
Test Error:
 Accuracy: 42.7%, Avg loss: 0.721685

loss: 0.720689  [    0/  398]
Test Error:
 Accuracy: 46.8%, Avg loss: 0.717670

loss: 0.695618  [    0/  398]
Test Error:
 Accuracy: 49.7%, Avg loss: 0.710449

loss: 0.711300  [    0/  398]
Test Error:
 Accuracy: 54.4%, Avg loss: 0.706370

loss: 0.713532  [    0/  398]
Test Error:
 Accuracy: 57.3%, Avg loss: 0.698496

loss: 0.701890  [    0/  398]
Test Error:
 Accuracy: 58.5%, Avg loss: 0.691617

loss: 0.690692  [    0/  398]
Test Error:
 Accuracy: 61.4%, Avg loss: 0.685756

loss: 0.693453  [    0/  398]
Test Error:
 Accuracy: 62.6%, Avg loss: 0.678358

loss: 0.673729  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.674855

Running experiment with Tanh, SGD, LR=0.0001, Batch=64
loss: 0.705977  [    0/  398]
Test Error:
 Accuracy: 37.4%, Avg loss: 0.702425

loss: 0.698833  [    0/  398]
Test Error:
 Accuracy: 40.9%, Avg loss: 0.698540

loss: 0.699504  [    0/  398]
Test Error:
 Accuracy: 43.9%, Avg loss: 0.697372

loss: 0.697436  [    0/  398]
Test Error:
 Accuracy: 47.4%, Avg loss: 0.693579

loss: 0.688744  [    0/  398]
Test Error:
 Accuracy: 51.5%, Avg loss: 0.691357

loss: 0.685976  [    0/  398]
Test Error:
 Accuracy: 55.6%, Avg loss: 0.687170

loss: 0.680839  [    0/  398]
Test Error:
 Accuracy: 57.3%, Avg loss: 0.684585

loss: 0.693055  [    0/  398]
Test Error:
 Accuracy: 60.2%, Avg loss: 0.681337

loss: 0.685436  [    0/  398]
Test Error:
 Accuracy: 62.6%, Avg loss: 0.677081

loss: 0.683882  [    0/  398]
Test Error:
 Accuracy: 66.7%, Avg loss: 0.674602

Running experiment with Tanh, Adam, LR=0.001, Batch=32
loss: 0.695279  [    0/  398]
Test Error:
 Accuracy: 94.2%, Avg loss: 0.163078

loss: 0.172323  [    0/  398]
Test Error:
 Accuracy: 94.7%, Avg loss: 0.155602

loss: 0.214578  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.197203

loss: 0.006535  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.178387

loss: 0.007680  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.233518

loss: 0.003241  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.197444

loss: 0.016212  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.182312

loss: 0.021697  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.173336

loss: 0.031990  [    0/  398]
Test Error:
 Accuracy: 94.7%, Avg loss: 0.209038

loss: 0.001106  [    0/  398]
Test Error:
 Accuracy: 94.7%, Avg loss: 0.210245

Running experiment with Tanh, Adam, LR=0.001, Batch=64
loss: 0.687885  [    0/  398]
Test Error:
 Accuracy: 95.9%, Avg loss: 0.111520

loss: 0.146017  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.157237

loss: 0.026546  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.149856

loss: 0.028705  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.180212

loss: 0.013166  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.178271

loss: 0.022169  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.191312

loss: 0.013602  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.193269

loss: 0.016167  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.195088

loss: 0.009361  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.200763

loss: 0.006859  [    0/  398]
Test Error:
 Accuracy: 94.7%, Avg loss: 0.212720

Running experiment with Tanh, Adam, LR=0.0001, Batch=32
loss: 0.731552  [    0/  398]
Test Error:
 Accuracy: 95.9%, Avg loss: 0.304736

loss: 0.312383  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.187281

loss: 0.138851  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.140723

loss: 0.133901  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.124157

loss: 0.123922  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.122802

loss: 0.081772  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.123682

loss: 0.152787  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.147745

loss: 0.042530  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.118237

loss: 0.061266  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.107943

loss: 0.060623  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.112699

Running experiment with Tanh, Adam, LR=0.0001, Batch=64
loss: 0.725449  [    0/  398]
Test Error:
 Accuracy: 92.4%, Avg loss: 0.435443

loss: 0.409800  [    0/  398]
Test Error:
 Accuracy: 94.2%, Avg loss: 0.289457

loss: 0.259194  [    0/  398]
Test Error:
 Accuracy: 94.7%, Avg loss: 0.224702

loss: 0.202516  [    0/  398]
Test Error:
 Accuracy: 95.9%, Avg loss: 0.187966

loss: 0.144088  [    0/  398]
Test Error:
 Accuracy: 95.9%, Avg loss: 0.163797

loss: 0.133339  [    0/  398]
Test Error:
 Accuracy: 95.9%, Avg loss: 0.150692

loss: 0.139501  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.143200

loss: 0.129634  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.139924

loss: 0.103436  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.136252

loss: 0.071650  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.138120

Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.5)
Path to dataset files: C:\Users\crist\.cache\kagglehub\datasets\uciml\breast-cancer-wisconsin-data\versions\2
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 569 entries, 0 to 568
Data columns (total 33 columns):
 #   Column                   Non-Null Count  Dtype
---  ------                   --------------  -----
 0   id                       569 non-null    int64
 1   diagnosis                569 non-null    object
 2   radius_mean              569 non-null    float64
 3   texture_mean             569 non-null    float64
 4   perimeter_mean           569 non-null    float64
 5   area_mean                569 non-null    float64
 6   smoothness_mean          569 non-null    float64
 7   compactness_mean         569 non-null    float64
 8   concavity_mean           569 non-null    float64
 9   concave points_mean      569 non-null    float64
 10  symmetry_mean            569 non-null    float64
 11  fractal_dimension_mean   569 non-null    float64
 12  radius_se                569 non-null    float64
 13  texture_se               569 non-null    float64
 14  perimeter_se             569 non-null    float64
 15  area_se                  569 non-null    float64
 16  smoothness_se            569 non-null    float64
 17  compactness_se           569 non-null    float64
 18  concavity_se             569 non-null    float64
 19  concave points_se        569 non-null    float64
 20  symmetry_se              569 non-null    float64
 21  fractal_dimension_se     569 non-null    float64
 22  radius_worst             569 non-null    float64
 23  texture_worst            569 non-null    float64
 24  perimeter_worst          569 non-null    float64
 25  area_worst               569 non-null    float64
 26  smoothness_worst         569 non-null    float64
 27  compactness_worst        569 non-null    float64
 28  concavity_worst          569 non-null    float64
 29  concave points_worst     569 non-null    float64
 30  symmetry_worst           569 non-null    float64
 31  fractal_dimension_worst  569 non-null    float64
 32  Unnamed: 32              0 non-null      float64
dtypes: float64(31), int64(1), object(1)
memory usage: 146.8+ KB
C:\Users\crist\AppData\Local\Temp\ipykernel_16836\1762497399.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  data['diagnosis'] = data['diagnosis'].replace({'M': 1, 'B': 0})
Shape of X [N, C, H, W]:  torch.Size([32, 30])
Shape of y:  torch.Size([32, 1]) torch.float32
Running experiment with ReLU, SGD, LR=0.001, Batch=32
loss: 0.688359  [    0/  398]
Running experiment with ReLU, SGD, LR=0.001, Batch=32
loss: 0.709944  [    0/  398]
Test Error:
 Accuracy: 41.5%, Avg loss: 0.693398

loss: 0.699534  [    0/  398]
Test Error:
 Accuracy: 53.2%, Avg loss: 0.685747

loss: 0.691332  [    0/  398]
Test Error:
 Accuracy: 66.1%, Avg loss: 0.676836

loss: 0.662389  [    0/  398]
Test Error:
 Accuracy: 76.6%, Avg loss: 0.668112

loss: 0.682667  [    0/  398]
Test Error:
 Accuracy: 82.5%, Avg loss: 0.661717

loss: 0.663878  [    0/  398]
Test Error:
 Accuracy: 86.5%, Avg loss: 0.652548

loss: 0.665363  [    0/  398]
Test Error:
 Accuracy: 88.3%, Avg loss: 0.647608

loss: 0.637965  [    0/  398]
Test Error:
 Accuracy: 90.1%, Avg loss: 0.639471

loss: 0.633568  [    0/  398]
Test Error:
 Accuracy: 91.2%, Avg loss: 0.633787

loss: 0.628375  [    0/  398]
Test Error:
 Accuracy: 92.4%, Avg loss: 0.630355

Running experiment with ReLU, SGD, LR=0.001, Batch=64
loss: 0.717484  [    0/  398]
Test Error:
 Accuracy: 37.4%, Avg loss: 0.710375

loss: 0.707894  [    0/  398]
Test Error:
 Accuracy: 38.0%, Avg loss: 0.704293

loss: 0.699719  [    0/  398]
Test Error:
 Accuracy: 40.9%, Avg loss: 0.700486

loss: 0.696592  [    0/  398]
Test Error:
 Accuracy: 42.1%, Avg loss: 0.693828

loss: 0.686035  [    0/  398]
Test Error:
 Accuracy: 45.6%, Avg loss: 0.689081

loss: 0.684688  [    0/  398]
Test Error:
 Accuracy: 51.5%, Avg loss: 0.684280

loss: 0.671480  [    0/  398]
Test Error:
 Accuracy: 58.5%, Avg loss: 0.679439

loss: 0.670205  [    0/  398]
Test Error:
 Accuracy: 64.3%, Avg loss: 0.673070

loss: 0.668617  [    0/  398]
Test Error:
 Accuracy: 70.8%, Avg loss: 0.669779

loss: 0.665393  [    0/  398]
Test Error:
 Accuracy: 78.9%, Avg loss: 0.665469

Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.5)
Path to dataset files: C:\Users\crist\.cache\kagglehub\datasets\uciml\breast-cancer-wisconsin-data\versions\2
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 569 entries, 0 to 568
Data columns (total 33 columns):
 #   Column                   Non-Null Count  Dtype
---  ------                   --------------  -----
 0   id                       569 non-null    int64
 1   diagnosis                569 non-null    object
 2   radius_mean              569 non-null    float64
 3   texture_mean             569 non-null    float64
 4   perimeter_mean           569 non-null    float64
 5   area_mean                569 non-null    float64
 6   smoothness_mean          569 non-null    float64
 7   compactness_mean         569 non-null    float64
 8   concavity_mean           569 non-null    float64
 9   concave points_mean      569 non-null    float64
 10  symmetry_mean            569 non-null    float64
 11  fractal_dimension_mean   569 non-null    float64
 12  radius_se                569 non-null    float64
 13  texture_se               569 non-null    float64
 14  perimeter_se             569 non-null    float64
 15  area_se                  569 non-null    float64
 16  smoothness_se            569 non-null    float64
 17  compactness_se           569 non-null    float64
 18  concavity_se             569 non-null    float64
 19  concave points_se        569 non-null    float64
 20  symmetry_se              569 non-null    float64
 21  fractal_dimension_se     569 non-null    float64
 22  radius_worst             569 non-null    float64
 23  texture_worst            569 non-null    float64
 24  perimeter_worst          569 non-null    float64
 25  area_worst               569 non-null    float64
 26  smoothness_worst         569 non-null    float64
 27  compactness_worst        569 non-null    float64
 28  concavity_worst          569 non-null    float64
 29  concave points_worst     569 non-null    float64
 30  symmetry_worst           569 non-null    float64
 31  fractal_dimension_worst  569 non-null    float64
 32  Unnamed: 32              0 non-null      float64
dtypes: float64(31), int64(1), object(1)
memory usage: 146.8+ KB
C:\Users\crist\AppData\Local\Temp\ipykernel_16836\1762497399.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  data['diagnosis'] = data['diagnosis'].replace({'M': 1, 'B': 0})
Shape of X [N, C, H, W]:  torch.Size([32, 30])
Shape of y:  torch.Size([32, 1]) torch.float32
Running experiment with ReLU, SGD, LR=0.001, Batch=32
loss: 0.686257  [    0/  398]
Test Error:
 Accuracy: 72.5%, Avg loss: 0.677934

loss: 0.676706  [    0/  398]
Test Error:
 Accuracy: 78.9%, Avg loss: 0.669590

loss: 0.667036  [    0/  398]
Test Error:
 Accuracy: 81.9%, Avg loss: 0.660507

loss: 0.655268  [    0/  398]
Test Error:
 Accuracy: 84.2%, Avg loss: 0.653263

loss: 0.652570  [    0/  398]
Test Error:
 Accuracy: 86.5%, Avg loss: 0.646111

loss: 0.657078  [    0/  398]
Test Error:
 Accuracy: 87.7%, Avg loss: 0.640315

loss: 0.661143  [    0/  398]
Test Error:
 Accuracy: 88.9%, Avg loss: 0.629919

loss: 0.622043  [    0/  398]
Test Error:
 Accuracy: 90.1%, Avg loss: 0.624343

loss: 0.624805  [    0/  398]
Test Error:
 Accuracy: 90.6%, Avg loss: 0.615413

loss: 0.619967  [    0/  398]
Test Error:
 Accuracy: 91.2%, Avg loss: 0.610565

Running experiment with ReLU, SGD, LR=0.001, Batch=64
loss: 0.672959  [    0/  398]
Test Error:
 Accuracy: 78.4%, Avg loss: 0.670805

loss: 0.668382  [    0/  398]
Test Error:
 Accuracy: 81.9%, Avg loss: 0.666182

loss: 0.665131  [    0/  398]
Test Error:
 Accuracy: 86.5%, Avg loss: 0.661558

loss: 0.663251  [    0/  398]
Test Error:
 Accuracy: 91.8%, Avg loss: 0.655187

loss: 0.653262  [    0/  398]
Test Error:
 Accuracy: 93.0%, Avg loss: 0.651477

loss: 0.649451  [    0/  398]
Test Error:
 Accuracy: 94.2%, Avg loss: 0.645975

loss: 0.651080  [    0/  398]
Test Error:
 Accuracy: 94.7%, Avg loss: 0.641164

loss: 0.641803  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.637641

loss: 0.638037  [    0/  398]
Test Error:
 Accuracy: 94.7%, Avg loss: 0.631412

loss: 0.633668  [    0/  398]
Test Error:
 Accuracy: 94.7%, Avg loss: 0.627859

Running experiment with ReLU, SGD, LR=0.0001, Batch=32
loss: 0.708275  [    0/  398]
Test Error:
 Accuracy: 24.0%, Avg loss: 0.719438

loss: 0.725157  [    0/  398]
Test Error:
 Accuracy: 24.6%, Avg loss: 0.720057

loss: 0.722072  [    0/  398]
Test Error:
 Accuracy: 24.6%, Avg loss: 0.717002

loss: 0.701817  [    0/  398]
Test Error:
 Accuracy: 25.1%, Avg loss: 0.716546

loss: 0.710450  [    0/  398]
Test Error:
 Accuracy: 25.1%, Avg loss: 0.715867

loss: 0.718055  [    0/  398]
Test Error:
 Accuracy: 25.1%, Avg loss: 0.713065

loss: 0.715082  [    0/  398]
Test Error:
 Accuracy: 25.1%, Avg loss: 0.713331

loss: 0.710357  [    0/  398]
Test Error:
 Accuracy: 25.7%, Avg loss: 0.711443

loss: 0.711403  [    0/  398]
Test Error:
 Accuracy: 28.1%, Avg loss: 0.711789

loss: 0.719819  [    0/  398]
Test Error:
 Accuracy: 30.4%, Avg loss: 0.709622

Running experiment with ReLU, SGD, LR=0.0001, Batch=64
loss: 0.699363  [    0/  398]
Test Error:
 Accuracy: 51.5%, Avg loss: 0.694277

loss: 0.694563  [    0/  398]
Test Error:
 Accuracy: 52.6%, Avg loss: 0.694085

loss: 0.686642  [    0/  398]
Test Error:
 Accuracy: 52.6%, Avg loss: 0.693340

loss: 0.690647  [    0/  398]
Test Error:
 Accuracy: 52.6%, Avg loss: 0.691523

loss: 0.688082  [    0/  398]
Test Error:
 Accuracy: 52.6%, Avg loss: 0.690412

loss: 0.687882  [    0/  398]
Test Error:
 Accuracy: 53.8%, Avg loss: 0.690784

loss: 0.689243  [    0/  398]
Test Error:
 Accuracy: 53.8%, Avg loss: 0.690477

loss: 0.692290  [    0/  398]
Test Error:
 Accuracy: 53.8%, Avg loss: 0.689640

loss: 0.689330  [    0/  398]
Test Error:
 Accuracy: 53.8%, Avg loss: 0.689350

loss: 0.683355  [    0/  398]
Test Error:
 Accuracy: 54.4%, Avg loss: 0.689956

Running experiment with ReLU, Adam, LR=0.001, Batch=32
loss: 0.712643  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.079577

loss: 0.070869  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.069591

loss: 0.035175  [    0/  398]
Test Error:
 Accuracy: 97.7%, Avg loss: 0.062057

loss: 0.068404  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.061700

loss: 0.011696  [    0/  398]
Test Error:
 Accuracy: 97.7%, Avg loss: 0.059036

loss: 0.108844  [    0/  398]
Test Error:
 Accuracy: 97.7%, Avg loss: 0.059580

loss: 0.005628  [    0/  398]
Test Error:
 Accuracy: 98.2%, Avg loss: 0.066141

loss: 0.058214  [    0/  398]
Test Error:
 Accuracy: 98.2%, Avg loss: 0.060999

loss: 0.008599  [    0/  398]
Test Error:
 Accuracy: 97.7%, Avg loss: 0.067760

loss: 0.003120  [    0/  398]
Test Error:
 Accuracy: 98.2%, Avg loss: 0.064727

Running experiment with ReLU, Adam, LR=0.001, Batch=64
loss: 0.662427  [    0/  398]
Test Error:
 Accuracy: 94.7%, Avg loss: 0.123695

loss: 0.160065  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.073889

loss: 0.071244  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.066127

loss: 0.040608  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.060571

loss: 0.012657  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.065511

loss: 0.018985  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.070312

loss: 0.020004  [    0/  398]
Test Error:
 Accuracy: 97.7%, Avg loss: 0.061316

loss: 0.013079  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.067908

loss: 0.016643  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.067505

loss: 0.030219  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.068567

Running experiment with ReLU, Adam, LR=0.0001, Batch=32
loss: 0.700315  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.504905

loss: 0.488428  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.357060

loss: 0.387013  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.272302

loss: 0.250612  [    0/  398]
Test Error:
 Accuracy: 95.9%, Avg loss: 0.194169

loss: 0.170848  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.159032

loss: 0.218497  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.140649

loss: 0.178067  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.124111

loss: 0.136323  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.104781

loss: 0.106192  [    0/  398]
Test Error:
 Accuracy: 97.7%, Avg loss: 0.100095

loss: 0.064184  [    0/  398]
Test Error:
 Accuracy: 97.7%, Avg loss: 0.099071

Running experiment with ReLU, Adam, LR=0.0001, Batch=64
loss: 0.671771  [    0/  398]
Test Error:
 Accuracy: 94.7%, Avg loss: 0.546526

loss: 0.548537  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.439824

loss: 0.436842  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.363035

loss: 0.363579  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.295380

loss: 0.268807  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.250111

loss: 0.265629  [    0/  398]
Test Error:
 Accuracy: 95.9%, Avg loss: 0.211280

loss: 0.229616  [    0/  398]
Test Error:
 Accuracy: 95.9%, Avg loss: 0.175459

loss: 0.200115  [    0/  398]
Test Error:
 Accuracy: 95.9%, Avg loss: 0.160857

loss: 0.155280  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.140254

loss: 0.142775  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.133000

Running experiment with Sigmoid, SGD, LR=0.001, Batch=32
loss: 0.700877  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.667437

loss: 0.640858  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.656630

loss: 0.650192  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.654120

loss: 0.656235  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.642037

loss: 0.654240  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.647208

loss: 0.664665  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.645453

loss: 0.702356  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.643468

loss: 0.690685  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.637918

loss: 0.689183  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.646018

loss: 0.603205  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.646904

Running experiment with Sigmoid, SGD, LR=0.001, Batch=64
loss: 0.707784  [    0/  398]
Test Error:
 Accuracy: 32.7%, Avg loss: 0.707323

loss: 0.701520  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.690694

loss: 0.691725  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.681837

loss: 0.687457  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.670067

loss: 0.666274  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.663743

loss: 0.657814  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.656292

loss: 0.670123  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.651770

loss: 0.659260  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.654810

loss: 0.697380  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.651414

loss: 0.660637  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.647084

Running experiment with Sigmoid, SGD, LR=0.0001, Batch=32
loss: 0.687312  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.677920

loss: 0.677109  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.675114

loss: 0.692521  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.673735

loss: 0.683295  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.669376

loss: 0.681990  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.665530

loss: 0.678051  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.667369

loss: 0.691523  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.670852

loss: 0.675089  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.663986

loss: 0.665265  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.663026

loss: 0.697804  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.669583

Running experiment with Sigmoid, SGD, LR=0.0001, Batch=64
loss: 0.708954  [    0/  398]
Test Error:
 Accuracy: 32.7%, Avg loss: 0.719993

loss: 0.715451  [    0/  398]
Test Error:
 Accuracy: 32.7%, Avg loss: 0.718604

loss: 0.714155  [    0/  398]
Test Error:
 Accuracy: 32.7%, Avg loss: 0.715972

loss: 0.725713  [    0/  398]
Test Error:
 Accuracy: 32.7%, Avg loss: 0.713123

loss: 0.716499  [    0/  398]
Test Error:
 Accuracy: 32.7%, Avg loss: 0.709742

loss: 0.702891  [    0/  398]
Test Error:
 Accuracy: 32.7%, Avg loss: 0.708888

loss: 0.704874  [    0/  398]
Test Error:
 Accuracy: 32.7%, Avg loss: 0.706067

loss: 0.700181  [    0/  398]
Test Error:
 Accuracy: 32.7%, Avg loss: 0.704567

loss: 0.695231  [    0/  398]
Test Error:
 Accuracy: 32.2%, Avg loss: 0.702541

loss: 0.702458  [    0/  398]
Test Error:
 Accuracy: 32.2%, Avg loss: 0.700133

Running experiment with Sigmoid, Adam, LR=0.001, Batch=32
loss: 0.686211  [    0/  398]
Test Error:
 Accuracy: 89.5%, Avg loss: 0.488218

loss: 0.493144  [    0/  398]
Test Error:
 Accuracy: 93.0%, Avg loss: 0.275149

loss: 0.243603  [    0/  398]
Test Error:
 Accuracy: 94.2%, Avg loss: 0.159957

loss: 0.202312  [    0/  398]
Test Error:
 Accuracy: 95.9%, Avg loss: 0.126414

loss: 0.272645  [    0/  398]
Test Error:
 Accuracy: 95.9%, Avg loss: 0.089675

loss: 0.204042  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.084421

loss: 0.056228  [    0/  398]
Test Error:
 Accuracy: 97.7%, Avg loss: 0.101187

loss: 0.065917  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.080977

loss: 0.041441  [    0/  398]
Test Error:
 Accuracy: 98.2%, Avg loss: 0.072345

loss: 0.020370  [    0/  398]
Test Error:
 Accuracy: 98.2%, Avg loss: 0.066184

Running experiment with Sigmoid, Adam, LR=0.001, Batch=64
loss: 0.684010  [    0/  398]
Test Error:
 Accuracy: 90.1%, Avg loss: 0.479233

loss: 0.499522  [    0/  398]
Test Error:
 Accuracy: 92.4%, Avg loss: 0.284618

loss: 0.322874  [    0/  398]
Test Error:
 Accuracy: 93.6%, Avg loss: 0.185984

loss: 0.213509  [    0/  398]
Test Error:
 Accuracy: 94.2%, Avg loss: 0.128903

loss: 0.106502  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.103465

loss: 0.158591  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.088222

loss: 0.053473  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.087666

loss: 0.073930  [    0/  398]
Test Error:
 Accuracy: 98.2%, Avg loss: 0.071666

loss: 0.070685  [    0/  398]
Test Error:
 Accuracy: 97.7%, Avg loss: 0.074893

loss: 0.061357  [    0/  398]
Test Error:
 Accuracy: 97.7%, Avg loss: 0.069653

Running experiment with Sigmoid, Adam, LR=0.0001, Batch=32
loss: 0.684401  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.608967

loss: 0.652122  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.598396

loss: 0.685841  [    0/  398]
Test Error:
 Accuracy: 72.5%, Avg loss: 0.570789

loss: 0.537108  [    0/  398]
Test Error:
 Accuracy: 77.2%, Avg loss: 0.535830

loss: 0.576360  [    0/  398]
Test Error:
 Accuracy: 84.8%, Avg loss: 0.503593

loss: 0.561088  [    0/  398]
Test Error:
 Accuracy: 87.7%, Avg loss: 0.474857

loss: 0.504045  [    0/  398]
Test Error:
 Accuracy: 86.5%, Avg loss: 0.432666

loss: 0.497382  [    0/  398]
Test Error:
 Accuracy: 90.6%, Avg loss: 0.394562

loss: 0.399349  [    0/  398]
Test Error:
 Accuracy: 92.4%, Avg loss: 0.373206

loss: 0.356516  [    0/  398]
Test Error:
 Accuracy: 94.2%, Avg loss: 0.346187

Running experiment with Sigmoid, Adam, LR=0.0001, Batch=64
loss: 0.707517  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.637311

loss: 0.667415  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.615774

loss: 0.687273  [    0/  398]
Test Error:
 Accuracy: 67.3%, Avg loss: 0.599902

loss: 0.608479  [    0/  398]
Test Error:
 Accuracy: 67.8%, Avg loss: 0.580868

loss: 0.632685  [    0/  398]
Test Error:
 Accuracy: 70.8%, Avg loss: 0.564874

loss: 0.605906  [    0/  398]
Test Error:
 Accuracy: 73.1%, Avg loss: 0.538378

loss: 0.565299  [    0/  398]
Test Error:
 Accuracy: 77.8%, Avg loss: 0.524651

loss: 0.530930  [    0/  398]
Test Error:
 Accuracy: 83.0%, Avg loss: 0.498470

loss: 0.532283  [    0/  398]
Test Error:
 Accuracy: 86.0%, Avg loss: 0.483238

loss: 0.511787  [    0/  398]
Test Error:
 Accuracy: 88.9%, Avg loss: 0.463191

Running experiment with Tanh, SGD, LR=0.001, Batch=32
loss: 0.653964  [    0/  398]
Test Error:
 Accuracy: 87.1%, Avg loss: 0.599012

loss: 0.597984  [    0/  398]
Test Error:
 Accuracy: 91.8%, Avg loss: 0.563374

loss: 0.583357  [    0/  398]
Test Error:
 Accuracy: 91.2%, Avg loss: 0.523669

loss: 0.515810  [    0/  398]
Test Error:
 Accuracy: 92.4%, Avg loss: 0.494644

loss: 0.465431  [    0/  398]
Test Error:
 Accuracy: 93.0%, Avg loss: 0.477546

loss: 0.481412  [    0/  398]
Test Error:
 Accuracy: 93.6%, Avg loss: 0.448845

loss: 0.417656  [    0/  398]
Test Error:
 Accuracy: 94.2%, Avg loss: 0.427103

loss: 0.436345  [    0/  398]
Test Error:
 Accuracy: 94.2%, Avg loss: 0.408007

loss: 0.393557  [    0/  398]
Test Error:
 Accuracy: 93.6%, Avg loss: 0.394129

loss: 0.406398  [    0/  398]
Test Error:
 Accuracy: 93.6%, Avg loss: 0.386997

Running experiment with Tanh, SGD, LR=0.001, Batch=64
loss: 0.732046  [    0/  398]
Test Error:
 Accuracy: 56.7%, Avg loss: 0.694119

loss: 0.695576  [    0/  398]
Test Error:
 Accuracy: 77.2%, Avg loss: 0.665722

loss: 0.666611  [    0/  398]
Test Error:
 Accuracy: 85.4%, Avg loss: 0.637621

loss: 0.647735  [    0/  398]
Test Error:
 Accuracy: 88.9%, Avg loss: 0.612645

loss: 0.618495  [    0/  398]
Test Error:
 Accuracy: 93.0%, Avg loss: 0.592525

loss: 0.593896  [    0/  398]
Test Error:
 Accuracy: 93.0%, Avg loss: 0.568262

loss: 0.580498  [    0/  398]
Test Error:
 Accuracy: 94.2%, Avg loss: 0.547194

loss: 0.560036  [    0/  398]
Test Error:
 Accuracy: 94.2%, Avg loss: 0.530368

loss: 0.521253  [    0/  398]
Test Error:
 Accuracy: 94.2%, Avg loss: 0.513369

loss: 0.511809  [    0/  398]
Test Error:
 Accuracy: 94.7%, Avg loss: 0.495960

Running experiment with Tanh, SGD, LR=0.0001, Batch=32
loss: 0.696011  [    0/  398]
Test Error:
 Accuracy: 57.3%, Avg loss: 0.688431

loss: 0.684506  [    0/  398]
Test Error:
 Accuracy: 63.7%, Avg loss: 0.682449

loss: 0.689140  [    0/  398]
Test Error:
 Accuracy: 69.0%, Avg loss: 0.677959

loss: 0.674324  [    0/  398]
Test Error:
 Accuracy: 74.9%, Avg loss: 0.671377

loss: 0.656124  [    0/  398]
Test Error:
 Accuracy: 80.1%, Avg loss: 0.669582

loss: 0.663987  [    0/  398]
Test Error:
 Accuracy: 81.9%, Avg loss: 0.661057

loss: 0.662652  [    0/  398]
Test Error:
 Accuracy: 86.5%, Avg loss: 0.656412

loss: 0.659034  [    0/  398]
Test Error:
 Accuracy: 87.1%, Avg loss: 0.649575

loss: 0.649931  [    0/  398]
Test Error:
 Accuracy: 88.9%, Avg loss: 0.642542

loss: 0.628653  [    0/  398]
Test Error:
 Accuracy: 89.5%, Avg loss: 0.637964

Running experiment with Tanh, SGD, LR=0.0001, Batch=64
loss: 0.718961  [    0/  398]
Test Error:
 Accuracy: 21.6%, Avg loss: 0.719794

loss: 0.727428  [    0/  398]
Test Error:
 Accuracy: 23.4%, Avg loss: 0.717632

loss: 0.710320  [    0/  398]
Test Error:
 Accuracy: 27.5%, Avg loss: 0.715078

loss: 0.711092  [    0/  398]
Test Error:
 Accuracy: 31.6%, Avg loss: 0.713062

loss: 0.703187  [    0/  398]
Test Error:
 Accuracy: 35.1%, Avg loss: 0.708748

loss: 0.703768  [    0/  398]
Test Error:
 Accuracy: 37.4%, Avg loss: 0.706229

loss: 0.708739  [    0/  398]
Test Error:
 Accuracy: 40.4%, Avg loss: 0.703807

loss: 0.693659  [    0/  398]
Test Error:
 Accuracy: 42.7%, Avg loss: 0.699543

loss: 0.699476  [    0/  398]
Test Error:
 Accuracy: 45.6%, Avg loss: 0.697243

loss: 0.689707  [    0/  398]
Test Error:
 Accuracy: 47.4%, Avg loss: 0.695096

Running experiment with Tanh, Adam, LR=0.001, Batch=32
loss: 0.704176  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.064342

loss: 0.042060  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.081427

loss: 0.032246  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.079091

loss: 0.015083  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.070682

loss: 0.007719  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.071586

loss: 0.065701  [    0/  398]
Test Error:
 Accuracy: 98.2%, Avg loss: 0.071487

loss: 0.023240  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.069830

loss: 0.015115  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.080298

loss: 0.011099  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.072988

loss: 0.024349  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.068957

Running experiment with Tanh, Adam, LR=0.001, Batch=64
loss: 0.682244  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.089366

loss: 0.086943  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.071366

loss: 0.087624  [    0/  398]
Test Error:
 Accuracy: 98.2%, Avg loss: 0.056763

loss: 0.144212  [    0/  398]
Test Error:
 Accuracy: 98.2%, Avg loss: 0.057939

loss: 0.133502  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.079449

loss: 0.058243  [    0/  398]
Test Error:
 Accuracy: 95.9%, Avg loss: 0.080833

loss: 0.158455  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.076240

loss: 0.055093  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.069346

loss: 0.053678  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.078040

loss: 0.019208  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.084620

Running experiment with Tanh, Adam, LR=0.0001, Batch=32
loss: 0.700064  [    0/  398]
Test Error:
 Accuracy: 93.0%, Avg loss: 0.291273

loss: 0.223329  [    0/  398]
Test Error:
 Accuracy: 94.7%, Avg loss: 0.185567

loss: 0.140369  [    0/  398]
Test Error:
 Accuracy: 95.9%, Avg loss: 0.134746

loss: 0.109136  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.117055

loss: 0.151034  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.102066

loss: 0.120658  [    0/  398]
Test Error:
 Accuracy: 98.2%, Avg loss: 0.114237

loss: 0.095253  [    0/  398]
Test Error:
 Accuracy: 97.7%, Avg loss: 0.083055

loss: 0.059408  [    0/  398]
Test Error:
 Accuracy: 98.2%, Avg loss: 0.083332

loss: 0.106353  [    0/  398]
Test Error:
 Accuracy: 98.2%, Avg loss: 0.090965

loss: 0.037859  [    0/  398]
Test Error:
 Accuracy: 98.2%, Avg loss: 0.097860

Running experiment with Tanh, Adam, LR=0.0001, Batch=64
loss: 0.704365  [    0/  398]
Test Error:
 Accuracy: 94.7%, Avg loss: 0.397752

loss: 0.385588  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.270715

loss: 0.231633  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.196398

loss: 0.218639  [    0/  398]
Test Error:
 Accuracy: 95.3%, Avg loss: 0.157383

loss: 0.215656  [    0/  398]
Test Error:
 Accuracy: 95.9%, Avg loss: 0.141589

loss: 0.147838  [    0/  398]
Test Error:
 Accuracy: 95.9%, Avg loss: 0.125902

loss: 0.119421  [    0/  398]
Test Error:
 Accuracy: 95.9%, Avg loss: 0.111298

loss: 0.173122  [    0/  398]
Test Error:
 Accuracy: 96.5%, Avg loss: 0.104339

loss: 0.101950  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.099095

loss: 0.063142  [    0/  398]
Test Error:
 Accuracy: 97.1%, Avg loss: 0.096743

Training and testing completed!
